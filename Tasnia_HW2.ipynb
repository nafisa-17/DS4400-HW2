{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48c03adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e664498",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = pd.read_csv(\"kc_house_data.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Scale the data so that each feature has mean 0 and standard deviation 1.\n",
    "\n",
    "# Divide price by 1000 \n",
    "house['price'] = house['price'] / 1000\n",
    "train['price'] = train['price'] / 1000\n",
    "test['price'] = test['price'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11142a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing not needed columns \n",
    "\n",
    "cols_to_drop = ['price', 'zipcode', 'id', 'date', 'Unamed: 0']\n",
    "# Also drop 'Unnamed: 0' if present\n",
    "for df in [train, test]:\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        cols_to_drop_df = cols_to_drop + ['Unnamed: 0']\n",
    "    else:\n",
    "        cols_to_drop_df = cols_to_drop\n",
    "\n",
    "feature_cols = [c for c in train.columns if c not in cols_to_drop + ['Unnamed: 0']]\n",
    "\n",
    "# Standardize feature columns\n",
    "scaler = StandardScaler()\n",
    "train[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
    "test[feature_cols] = scaler.transform(test[feature_cols])\n",
    "house[feature_cols] = scaler.transform(house[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18urwyk26ml",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set feature means:\n",
      "bedrooms        -0.0\n",
      "bathrooms        0.0\n",
      "sqft_living      0.0\n",
      "sqft_lot        -0.0\n",
      "floors          -0.0\n",
      "waterfront      -0.0\n",
      "view            -0.0\n",
      "condition       -0.0\n",
      "grade            0.0\n",
      "sqft_above      -0.0\n",
      "sqft_basement    0.0\n",
      "yr_built         0.0\n",
      "yr_renovated     0.0\n",
      "lat             -0.0\n",
      "long            -0.0\n",
      "sqft_living15   -0.0\n",
      "sqft_lot15       0.0\n",
      "dtype: float64\n",
      "Training set feature stds:\n",
      "bedrooms         1.0005\n",
      "bathrooms        1.0005\n",
      "sqft_living      1.0005\n",
      "sqft_lot         1.0005\n",
      "floors           1.0005\n",
      "waterfront       1.0005\n",
      "view             1.0005\n",
      "condition        1.0005\n",
      "grade            1.0005\n",
      "sqft_above       1.0005\n",
      "sqft_basement    1.0005\n",
      "yr_built         1.0005\n",
      "yr_renovated     1.0005\n",
      "lat              1.0005\n",
      "long             1.0005\n",
      "sqft_living15    1.0005\n",
      "sqft_lot15       1.0005\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# checking to see if the mean is 0 and std is 1\n",
    "print(\"Training set feature means:\")\n",
    "print(train[feature_cols].mean().round(6))\n",
    "\n",
    "\n",
    "print(\"Training set feature stds:\")\n",
    "print(train[feature_cols].std().round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "606a455d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 int64\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms         float64\n",
       "bathrooms        float64\n",
       "sqft_living      float64\n",
       "sqft_lot         float64\n",
       "floors           float64\n",
       "waterfront       float64\n",
       "view             float64\n",
       "condition        float64\n",
       "grade            float64\n",
       "sqft_above       float64\n",
       "sqft_basement    float64\n",
       "yr_built         float64\n",
       "yr_renovated     float64\n",
       "zipcode            int64\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15    float64\n",
       "sqft_lot15       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0856a3",
   "metadata": {},
   "source": [
    "# *[C]* Problem 2:  Linear regression (15 points)\n",
    "\n",
    "In this problem, you will use an existing package of your choice for training and testing a linear regression model for the house prediction\n",
    "dataset.\n",
    "\n",
    "1. Use an existing package to train a multiple linear regression model on the training set using all the features (except the ones excluded\n",
    "above). Report the coefficients of the linear regression models and the following metrics on the training data: (1) MSE metric; (2)\n",
    "$R^2$ metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5e385e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is what you use to predict\n",
    "X_train = train[feature_cols]\n",
    "\n",
    "# y is the TARGET (what you want to predict)\n",
    "y_train = train['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52acda21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether to calculate the intercept for this model. If set<br>to False, no intercept will be used in calculations<br>(i.e. data is expected to be centered).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If True, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=tol,-float%2C%20default%3D1e-6\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-6<br><br>The precision of the solution (`coef_`) is determined by `tol` which<br>specifies a different convergence criterion for the `lsqr` solver.<br>`tol` is set as `atol` and `btol` of :func:`scipy.sparse.linalg.lsqr` when<br>fitting on sparse training data. This parameter has no effect when fitting<br>on dense data.<br><br>.. versionadded:: 1.7</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use for the computation. This will only provide<br>speedup in case of sufficiently large problems, that is if firstly<br>`n_targets > 1` and secondly `X` is sparse or if `positive` is set<br>to `True`. ``None`` means 1 unless in a<br>:obj:`joblib.parallel_backend` context. ``-1`` means using all<br>processors. See :term:`Glossary <n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive. This<br>option is only supported for dense arrays.<br><br>For a comparison between a linear regression model with positive constraints<br>on the regression coefficients and a linear regression without such constraints,<br>see :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`.<br><br>.. versionadded:: 0.24</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using LinearRegression from SKLEARN I will solve this problem \n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf6b112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 520.4148\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grade</td>\n",
       "      <td>92.231475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lat</td>\n",
       "      <td>78.375737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yr_built</td>\n",
       "      <td>-67.643117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>63.742900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>56.748837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>48.290089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>view</td>\n",
       "      <td>48.200109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>45.577658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>27.137032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>18.527633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yr_renovated</td>\n",
       "      <td>17.271380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>condition</td>\n",
       "      <td>12.964269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>-12.930091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>-12.521962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>10.881868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>floors</td>\n",
       "      <td>8.043721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>long</td>\n",
       "      <td>-1.035203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Coefficient\n",
       "8           grade    92.231475\n",
       "13            lat    78.375737\n",
       "11       yr_built   -67.643117\n",
       "5      waterfront    63.742900\n",
       "2     sqft_living    56.748837\n",
       "9      sqft_above    48.290089\n",
       "6            view    48.200109\n",
       "15  sqft_living15    45.577658\n",
       "10  sqft_basement    27.137032\n",
       "1       bathrooms    18.527633\n",
       "12   yr_renovated    17.271380\n",
       "7       condition    12.964269\n",
       "16     sqft_lot15   -12.930091\n",
       "0        bedrooms   -12.521962\n",
       "3        sqft_lot    10.881868\n",
       "4          floors     8.043721\n",
       "14           long    -1.035203"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imporantance of the features \n",
    "cof = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': model.coef_\n",
    "})\n",
    "\n",
    "print(\"Intercept:\", round(model.intercept_, 4))\n",
    "print()\n",
    "cof.sort_values(by='Coefficient', ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a6fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict house prices for the training set\n",
    "y_pred_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1670e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 31486.17 r2: 0.73\n"
     ]
    }
   ],
   "source": [
    "# MSE and R squared Metrics\n",
    "mse = mean_squared_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train,y_pred_train)\n",
    "print('mse:', round(mse,2), 'r2:', round(r2,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a53f2",
   "metadata": {},
   "source": [
    "2. Evaluate the model on the testing set. Report the MSE and $R^2$ metrics on the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389dcf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is what you use to predict\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "# y is the TARGET (what you want to predict)\n",
    "y_test = test['price'].values\n",
    "\n",
    "# Use the ALREADY TRAINED model to predict on the test set\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69cf675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 57628.15 r2: 0.65\n"
     ]
    }
   ],
   "source": [
    "# RSE and MSE metrics\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print('mse:', round(mse_test,2), 'r2:', round(r2_test,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628c7d2",
   "metadata": {},
   "source": [
    "3. Interpret the results in your own words. Which features contribute mostly to the linear regression model? Is the model fitting the data\n",
    "well? How large is the model error? How do the training and testing MSE relate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0be3e",
   "metadata": {},
   "source": [
    "Since the features are standardized, the coefficents are directly comparable in magnitude a larger absolute coefficient means the feature has a greater impact on the predicted price. The features that contribute most to the model are the ones with the largest absolute coefficients (sqft_living, grade, lat, waterfront, view).\n",
    "\n",
    "The model fits the data reasonably well with an R^2 of 0.73 on training. This means about 73% of the variance in house prices can be explained. Since we divided price by 1000, the MSE values are much smaller and more interpertable. The testing MSE is higher since the model was optimized on the training data and may not generalize perfectly to data that hasn't been seen. The R^2 is also slightly lower on the test set, highlighting a small drop in performance on new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfb921",
   "metadata": {},
   "source": [
    "# *[C]* Problem 3:  Implementing closed-form solution for linear regression (15 points)\n",
    "\n",
    "In this problem, you will implement your own linear regression model, using the closed-form solution we derived in class. You will also\n",
    "compare your model with the one trained with the package in Problem 2 on the same house price prediction dataset.\n",
    "\n",
    "- Implement the closed-from solution for multiple linear regression using matrix operations and train a model on the training set. Write\n",
    "a function to predict the response on a new testing point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29eea7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Add intercept column\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        \n",
    "        # Closed-form solution\n",
    "        self.beta = np.linalg.solve(X_b.T @ X_b, X_b.T @ y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b @ self.beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85976c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine features for Problem 3 \n",
    "X_train_all = train[feature_cols].values\n",
    "y_train_all = train['price'].values\n",
    "\n",
    "X_test_all = test[feature_cols].values\n",
    "y_test_all = test['price'].values\n",
    "\n",
    "# Train closed-form model on training data\n",
    "my_model = MyLinearRegression()\n",
    "my_model.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fefc0269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 520.4148\n",
      "\n",
      "      Feature  Coefficient\n",
      "   sqft_above   132.944524\n",
      "        grade    92.231475\n",
      "          lat    78.375737\n",
      "sqft_basement    75.449424\n",
      "     yr_built   -67.643117\n",
      "   waterfront    63.742900\n",
      "         view    48.200109\n",
      "sqft_living15    45.577658\n",
      "  sqft_living   -38.390120\n",
      "    bathrooms    18.527633\n",
      " yr_renovated    17.271380\n",
      "    condition    12.964269\n",
      "   sqft_lot15   -12.930091\n",
      "     bedrooms   -12.521962\n",
      "     sqft_lot    10.881868\n",
      "       floors     8.043721\n",
      "         long    -1.035203\n"
     ]
    }
   ],
   "source": [
    "# Report coefficients\n",
    "print(\"Intercept:\", round(my_model.beta[0], 4))\n",
    "print()\n",
    "cf_coefs = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': my_model.beta[1:]\n",
    "})\n",
    "print(cf_coefs.sort_values(by='Coefficient', ascending=False, key=abs).to_string(index=False))\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred_cf = my_model.predict(X_train_all)\n",
    "mse_train_cf = mean_squared_error(y_train_all, y_train_pred_cf)\n",
    "r2_train_cf = r2_score(y_train_all, y_train_pred_cf)\n",
    "\n",
    "# Predict on testing set\n",
    "y_test_pred_cf = my_model.predict(X_test_all)\n",
    "mse_test_cf = mean_squared_error(y_test_all, y_test_pred_cf)\n",
    "r2_test_cf = r2_score(y_test_all, y_test_pred_cf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71f8925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3 (Closed-Form)\n",
      "Train MSE: 31486.17 Train R2: 0.73\n",
      "Test MSE: 57628.15 Test R2: 0.65\n",
      "Problem 2 (sklearn)\n",
      "Train MSE: 31486.17  Train R2: 0.73\n",
      "Test MSE: 57628.15  Test R2: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 3 (Closed-Form)\")\n",
    "print(\"Train MSE:\", round(mse_train_cf, 2), \"Train R2:\", round(r2_train_cf, 2))\n",
    "print(\"Test MSE:\", round(mse_test_cf, 2), \"Test R2:\", round(r2_test_cf, 2))\n",
    "\n",
    "print(\"Problem 2 (sklearn)\")\n",
    "print(\"Train MSE: 31486.17  Train R2: 0.73\")\n",
    "print(\"Test MSE: 57628.15  Test R2: 0.65\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a793a",
   "metadata": {},
   "source": [
    "Closed Form vs SKLEARN: \n",
    "\n",
    "The MSE and R^2 metrocs from my closed-form implementation is identical to SKLEARN's LinearRegression from problem 2. This is expected since sklearn's LinearRegression also uses the closed-form soultion internally. Both solve the same equation. The coefficents produced by both models differ. For example, SQFT_LIVING IS 56.75 in sklearn but -38.39 in the closed-form model, while sqft_above and sqft_basement shoft in the oppsite direction. This happens because sqft_above and sqft_basement are highly correlated. When features are correlated, there are multiple ways to split the wieght among them while still producing the same predictions. Overall both methods solve the same equation so it gives the same rpedictions and error metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a3456",
   "metadata": {},
   "source": [
    "# *[C]* Problem 4: Polynomial Regression (15 points)\n",
    "\n",
    "- Consider a feature $X$, a response variable $Y$, and $N$ samples of training data. Implement a polynomial regression model that fits a polynomial of degree $p$ to the data using the least-square method. Use your own implementation from Problem 3 and adapt it for polynomial\n",
    "regression. If $p=2$, the model will use two features ($X$ and $X^2$), if $p=3$ the model will use 3 features ($X,X^2,X^3$), and so on for larger values of $p$.\n",
    "- Consider the house price prediction problem with feature $X=$ `sqft_living`. Train a polynomial regression model for different values of $p \\le 5$ using your implementation. Include a table with the MSE and $R^2$ metrics on both the training and testing data for at least 3 different values of $p$. Discuss your observations on how the MSE and $R^2$ metrics change with the degree of the polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e369e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    def fit(self, X, y):\n",
    "        # Adds intercept column\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "        # Closed-form solution\n",
    "        self.beta = np.linalg.solve(X_b.T @ X_b, X_b.T @ y)\n",
    "\n",
    "    def predict(self, X):\n",
    "         # Add intercept column and compute predictions\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b @ self.beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cb6bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X, p):\n",
    "    # Generate polynomial features up to degree p (X, X^2,etc)\n",
    "    X_poly = np.column_stack([X**i for i in range(1, p+1)])\n",
    "    return X_poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a734c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature (sqft_living) and target (price) for training and testing sets\n",
    "X_train = train[['sqft_living']].values\n",
    "y_train = train['price'].values\n",
    "\n",
    "X_test = test[['sqft_living']].values\n",
    "y_test = test['price'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94409a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Degree</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57947.526161</td>\n",
       "      <td>88575.978543</td>\n",
       "      <td>0.496709</td>\n",
       "      <td>0.468736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>54822.665116</td>\n",
       "      <td>71791.679479</td>\n",
       "      <td>0.523849</td>\n",
       "      <td>0.569406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>53785.194716</td>\n",
       "      <td>99833.483763</td>\n",
       "      <td>0.532860</td>\n",
       "      <td>0.401216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>52626.111955</td>\n",
       "      <td>570616.914821</td>\n",
       "      <td>0.542927</td>\n",
       "      <td>-2.422464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Degree     Train MSE       Test MSE  Train R2   Test R2\n",
       "0       1  57947.526161   88575.978543  0.496709  0.468736\n",
       "1       2  54822.665116   71791.679479  0.523849  0.569406\n",
       "2       3  53785.194716   99833.483763  0.532860  0.401216\n",
       "3       5  52626.111955  570616.914821  0.542927 -2.422464"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store performance results for different polynomial degrees\n",
    "results = []\n",
    "\n",
    "for p in [1, 2, 3, 5]:\n",
    "    \n",
    "    # Generate polynomial features of degree p\n",
    "    X_train_poly = polynomial_features(X_train, p)\n",
    "    X_test_poly = polynomial_features(X_test, p)\n",
    "\n",
    "    # Train closed-form linear regression model\n",
    "    model = MyLinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Make predictions on training and testing data\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "\n",
    "    # Store evaluation metrics\n",
    "    results.append({\n",
    "        'Degree': p,\n",
    "        'Train MSE': mean_squared_error(y_train, y_train_pred),\n",
    "        'Test MSE': mean_squared_error(y_test, y_test_pred),\n",
    "        'Train R2': r2_score(y_train, y_train_pred),\n",
    "        'Test R2': r2_score(y_test, y_test_pred)\n",
    "    })\n",
    "\n",
    "# Convert results into a DataFrame for comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db742b45",
   "metadata": {},
   "source": [
    "As the polynomial degree increases, the training MSE decreases and trainoing R^2 increases. This makes sense because higher polynominals are more flexible, so they fit the training data better. Testing behaves differently. While moving from degree 1 to degree 2 improves both test MSE and test R^2, increasing the degree anymore leads to increase in test error and a decline in test R^2. For example, degree 5, the model overfits the data, resulting in a very large test MSE and a negative R^2 vaklue. This demonstrates the bias-variance tradeoff. Higher degree polynomials increase model flexibility and reduce bias but can significantly increase variance and hurt generalization performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c430e",
   "metadata": {},
   "source": [
    "# *[C]* Problem 5:  Gradient descent (20 points)\n",
    "\n",
    "In this problem, you will implement your own gradient descent algorithm and apply it to linear regression on the same house prediction dataset.\n",
    "\n",
    "1. Write code for gradient descent for training linear regression using the algorithm from class.\n",
    "2. Vary the value of the learning rate (at least 3 different values $\\alpha \\in \\{0.01,0.1,0.5\\}$) and report the value of the model parameter $\\theta$ after different number of iterations (10, 50, and 100). Include in a table the MSE and $R^2$ metrics on the training and testing set for the different number of iterations and different learning rates. You can choose more values of the learning rates to observe how the  behavior of the algorithm changes.\n",
    "3. Write some observations about the behavior of the algorithm: How do the metrics change with different learning rates; How many iterations are needed; Does the algorithm converge to the optimal solution, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b877a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD:\n",
    "    \n",
    "    def __init__(self, alpha=0.01, n_iters=1000):\n",
    "        self.alpha = alpha  # learning rate\n",
    "        self.n_iters = n_iters # number of iterations\n",
    "        self.theta = None # parameters\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        N, d = X.shape\n",
    "        \n",
    "        # Add intercept column\n",
    "        X = np.c_[np.ones((N, 1)), X]\n",
    "        \n",
    "        # Initialize theta\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = X @ self.theta\n",
    "            \n",
    "            # Compute gradient\n",
    "            gradient = (1/N) * (X.T @ (y_pred - y))\n",
    "            \n",
    "            # Update rule\n",
    "            self.theta = self.theta - self.alpha * gradient\n",
    "            \n",
    "            # Store loss (MSE)\n",
    "            loss = (1/(2*N)) * np.sum((y_pred - y)**2)\n",
    "            self.loss_history.append(loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        X = np.c_[np.ones((N, 1)), X]\n",
    "        return X @ self.theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d38c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all features for gradient descent on the house prediction dataset\n",
    "X_train_gd = train[feature_cols].values\n",
    "y_train_gd = train['price'].values\n",
    "\n",
    "X_test_gd = test[feature_cols].values\n",
    "y_test_gd = test['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "963c4f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>iterations</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>49.7610</td>\n",
       "      <td>2.947987e+05</td>\n",
       "      <td>3.505251e+05</td>\n",
       "      <td>-1.560400e+00</td>\n",
       "      <td>-1.102400e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>205.5607</td>\n",
       "      <td>1.382959e+05</td>\n",
       "      <td>1.703767e+05</td>\n",
       "      <td>-2.011000e-01</td>\n",
       "      <td>-2.190000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>329.9262</td>\n",
       "      <td>7.011899e+04</td>\n",
       "      <td>9.748624e+04</td>\n",
       "      <td>3.910000e-01</td>\n",
       "      <td>4.153000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>338.9574</td>\n",
       "      <td>6.649932e+04</td>\n",
       "      <td>9.355929e+04</td>\n",
       "      <td>4.224000e-01</td>\n",
       "      <td>4.388000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>517.7327</td>\n",
       "      <td>3.157898e+04</td>\n",
       "      <td>5.801232e+04</td>\n",
       "      <td>7.257000e-01</td>\n",
       "      <td>6.521000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>520.4010</td>\n",
       "      <td>3.149769e+04</td>\n",
       "      <td>5.772519e+04</td>\n",
       "      <td>7.264000e-01</td>\n",
       "      <td>6.538000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>519.9066</td>\n",
       "      <td>6.118299e+08</td>\n",
       "      <td>6.850231e+08</td>\n",
       "      <td>-5.312921e+03</td>\n",
       "      <td>-4.107652e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>520.4148</td>\n",
       "      <td>1.649496e+25</td>\n",
       "      <td>1.842083e+25</td>\n",
       "      <td>-1.432635e+20</td>\n",
       "      <td>-1.104850e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>-150582.1234</td>\n",
       "      <td>5.698752e+45</td>\n",
       "      <td>6.364111e+45</td>\n",
       "      <td>-4.949532e+40</td>\n",
       "      <td>-3.817086e+40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  iterations      theta_0     Train MSE      Test MSE      Train R2  \\\n",
       "0   0.01          10      49.7610  2.947987e+05  3.505251e+05 -1.560400e+00   \n",
       "1   0.01          50     205.5607  1.382959e+05  1.703767e+05 -2.011000e-01   \n",
       "2   0.01         100     329.9262  7.011899e+04  9.748624e+04  3.910000e-01   \n",
       "3   0.10          10     338.9574  6.649932e+04  9.355929e+04  4.224000e-01   \n",
       "4   0.10          50     517.7327  3.157898e+04  5.801232e+04  7.257000e-01   \n",
       "5   0.10         100     520.4010  3.149769e+04  5.772519e+04  7.264000e-01   \n",
       "6   0.50          10     519.9066  6.118299e+08  6.850231e+08 -5.312921e+03   \n",
       "7   0.50          50     520.4148  1.649496e+25  1.842083e+25 -1.432635e+20   \n",
       "8   0.50         100 -150582.1234  5.698752e+45  6.364111e+45 -4.949532e+40   \n",
       "\n",
       "        Test R2  \n",
       "0 -1.102400e+00  \n",
       "1 -2.190000e-02  \n",
       "2  4.153000e-01  \n",
       "3  4.388000e-01  \n",
       "4  6.521000e-01  \n",
       "5  6.538000e-01  \n",
       "6 -4.107652e+03  \n",
       "7 -1.104850e+20  \n",
       "8 -3.817086e+40  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define learning rates and number of iterations to test\n",
    "learning_rates = [0.01, 0.1, 0.5]\n",
    "iterations_list = [10, 50, 100]\n",
    "\n",
    "# Store results for comparison\n",
    "results = []\n",
    "\n",
    "# Loop over different learning rates and iteration counts\n",
    "for alpha in learning_rates:\n",
    "    for n_iter in iterations_list:\n",
    "        \n",
    "        # Initialize and train gradient descent model\n",
    "        model = LinearRegressionGD(alpha=alpha, n_iters=n_iter)\n",
    "        model.fit(X_train_gd, y_train_gd)\n",
    "\n",
    "        # Generate predictions on training and testing data\n",
    "        y_train_pred_gd = model.predict(X_train_gd)\n",
    "        y_test_pred_gd = model.predict(X_test_gd)\n",
    "\n",
    "        # Store model parameters and performance metrics\n",
    "        results.append({\n",
    "            \"alpha\": alpha,\n",
    "            \"iterations\": n_iter,\n",
    "            \"theta_0\": round(model.theta[0], 4),\n",
    "            \"Train MSE\": round(mean_squared_error(y_train_gd, y_train_pred_gd), 2),\n",
    "            \"Test MSE\": round(mean_squared_error(y_test_gd, y_test_pred_gd), 2),\n",
    "            \"Train R2\": round(r2_score(y_train_gd, y_train_pred_gd), 4),\n",
    "            \"Test R2\": round(r2_score(y_test_gd, y_test_pred_gd), 4)\n",
    "        })\n",
    "\n",
    "# Convert results into a DataFrame for easier comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results table\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f9404",
   "metadata": {},
   "source": [
    "The results show that the behavior of the gradient descent is highly sensitive to the choice of the learning rate. When the learning rate is small like alpha = 0.01 then the algorthim converges slowly. The MSE decreases and the R^2 increases gradually as the number of iterations grow from 10 to 100. When learning rate is moderate like alpha = 0.1 then the algorithm converges much fasterm reaching strong performance within about 50 iterations. Additional ierations only show minor imrpoveemnt. However, when the learning rate is too large lue alpha = 0.5 then the algrothim becomes unstable and diverges. It leads to extremely alrge MSE values and higher negative R^2 scores. This shows that the parmaters updates are oevrshooting the minium rather than approaching it. Overall gradient descent converges to the otpimal soutlion when the learning rate is chosen approately. Too small elads to too slow conevrgence, whiel too large elads to divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68cd7c",
   "metadata": {},
   "source": [
    "# *A/C]* Problem 6: Ridge regularization (20 points)\n",
    "\n",
    "In this problem, you will derive the optimal parameters for ridge regression and train ridge regression models with different regularization levels. In ridge regression, the loss function includes a regularization term:\n",
    "\n",
    "$J(\\theta) = \\sum_{i=1}^N(h_{\\theta}(x_i)-y_i)^2 + \\lambda \\sum_{j=1}^d \\theta_j^2$\n",
    "\n",
    "1. **[A]** Write the derivation of the closed form solution for parameter $\\theta$ that minimizes the loss function $J(\\theta)$ in ridge regression. done on paper.\n",
    "\n",
    "2. **[C]** Modify your implementation from Problem 5 to implement ridge regression with gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feec82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ridge Regression with Gradient Descent\n",
    "class RidgeRegressionGD:\n",
    "    def __init__(self, alpha=0.01, n_iters=5000, lam=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.n_iters = n_iters\n",
    "        self.lam = lam\n",
    "        self.theta = None\n",
    "        self.loss_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N, d = X.shape\n",
    "        Xb = np.c_[np.ones((N, 1)), X]\n",
    "        self.theta = np.zeros(d + 1)\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = Xb @ self.theta\n",
    "            error = y_pred - y\n",
    "\n",
    "            grad = (1/N) * (Xb.T @ error)\n",
    "\n",
    "            # Ridge penalty gradient (no regularization on intercept)\n",
    "            reg = (self.lam / N) * self.theta\n",
    "            reg[0] = 0.0\n",
    "\n",
    "            self.theta -= self.alpha * (grad + reg)\n",
    "\n",
    "            sse = np.sum(error**2)\n",
    "            penalty = self.lam * np.sum(self.theta[1:]**2)\n",
    "            self.loss_history.append(sse + penalty)\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        Xb = np.c_[np.ones((N, 1)), X]\n",
    "        return Xb @ self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4t0rwjzaf",
   "metadata": {},
   "source": [
    "### Part 3: Simulated Data with Ridge Regression\n",
    "\n",
    "Simulate $N=1000$ values of $X_i \\sim \\text{Uniform}(-2,2)$ and $Y_i = 1 + 2X_i + e_i$ where $e_i \\sim N(0,2)$. Fit with linear regression and ridge regression for $\\lambda \\in \\{1,10,100,1000,10000\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2gtpycous09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data and compare models \n",
    "np.random.seed(42)\n",
    "N = 1000\n",
    "X_sim = np.random.uniform(-2, 2, size=(N, 1))\n",
    "e = np.random.normal(0, 2, size=N)\n",
    "y_sim = 1 + 2 * X_sim.flatten() + e\n",
    "\n",
    "# Linear regression (lambda = 0)\n",
    "lr = LinearRegressionGD(alpha=0.01, n_iters=5000)\n",
    "lr.fit(X_sim, y_sim)\n",
    "y_pred_lr = lr.predict(X_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "770a21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (lambda = 0)\n",
      "Intercept: 1.1948\n",
      "Slope: 1.9226\n",
      "MSE: 3.8999\n",
      "R2: 0.5639\n",
      "\n",
      "Ridge Regression (lambda = 1 )\n",
      "Intercept: 1.1947\n",
      "Slope: 1.9212\n",
      "MSE: 3.8999\n",
      "R2: 0.5639\n",
      "\n",
      "Ridge Regression (lambda = 10 )\n",
      "Intercept: 1.1942\n",
      "Slope: 1.9086\n",
      "MSE: 3.9001\n",
      "R2: 0.5639\n",
      "\n",
      "Ridge Regression (lambda = 100 )\n",
      "Intercept: 1.1897\n",
      "Slope: 1.7913\n",
      "MSE: 3.9234\n",
      "R2: 0.5613\n",
      "\n",
      "Ridge Regression (lambda = 1000 )\n",
      "Intercept: 1.1631\n",
      "Slope: 1.1094\n",
      "MSE: 4.8021\n",
      "R2: 0.463\n",
      "\n",
      "Ridge Regression (lambda = 10000 )\n",
      "Intercept: 1.1288\n",
      "Slope: 0.2308\n",
      "MSE: 7.8044\n",
      "R2: 0.1273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression (lambda = 0)\")\n",
    "print(\"Intercept:\", round(lr.theta[0], 4))\n",
    "print(\"Slope:\", round(lr.theta[1], 4))\n",
    "print(\"MSE:\", round(mean_squared_error(y_sim, y_pred_lr), 4))\n",
    "print(\"R2:\", round(r2_score(y_sim, y_pred_lr), 4))\n",
    "print()\n",
    "\n",
    "lambdas = [1, 10, 100, 1000, 10000]\n",
    "\n",
    "for lam in lambdas:\n",
    "    ridge = RidgeRegressionGD(alpha=0.01, n_iters=5000, lam=lam)\n",
    "    ridge.fit(X_sim, y_sim)\n",
    "    y_pred_ridge = ridge.predict(X_sim)\n",
    "\n",
    "    print(\"Ridge Regression (lambda =\", lam, \")\")\n",
    "    print(\"Intercept:\", round(ridge.theta[0], 4))\n",
    "    print(\"Slope:\", round(ridge.theta[1], 4))\n",
    "    print(\"MSE:\", round(mean_squared_error(y_sim, y_pred_ridge), 4))\n",
    "    print(\"R2:\", round(r2_score(y_sim, y_pred_ridge), 4))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb963b1",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "As the regularization paramter $\\lambda$ increases:\n",
    "\n",
    "- the slope shrinks toward zero: With no regularization, the model estimates slope as 1.92. At $\\lambda$ = 1 and $\\lambda$ = 10, it remains around 1.91-1.92 but as $\\lambda$ = 1000 it drops to 1.11 and at $\\lambda$ = 10000 to only 0.23. This demonstrates ridge regression's penalty on large coefficients. \n",
    "\n",
    "- The intercept is minimally affected. Since ridge doesn't regularize the intercept, it stays near 1.19 across most $\\lambda$ values. It only drops at 1.13 at v = 10000.\n",
    "\n",
    "- MSE increases and R^2 decreases with largr $\\lambda$. For $\\lambda$ less than or equal to 10, MSE, remains 3.90 and r^2 0.56. At $\\lambda$ = 1000, MSE rises to 4.80 and R^2 drops to 0.46. At $\\lambda$ = 10000, MSE jumps to 7.80 and R^2 falls to 0.13, indicating severe underfitting.\n",
    "\n",
    "From this we can see that mild regularization has insignificant impact but excessive $\\lambda$ introduces bias and leads to underfitting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
